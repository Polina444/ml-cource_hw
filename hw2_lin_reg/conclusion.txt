Мой код реализует несколько функций потерь и их производные. В нем присутствуют функции потерь Mean Squared Error (MSE) и Mean Absolute Error (MAE), а также их производные по матрице весов w. Кроме того, в коде реализованы регуляризационные члены L2 и L1. Среднеквадратичная ошибка (MSE) вычисляется как среднее значение квадрата разности между предсказанными значениями и фактическими значениями целевой переменной. Она измеряет среднеквадратичное отклонение модели от истинных значений. Средняя абсолютная ошибка (MAE) вычисляется как среднее значение абсолютной разности между предсказанными значениями и фактическими значениями целевой переменной. Она измеряет среднее абсолютное отклонение модели от истинных значений. L2 регуляризация добавляет “штраф” к функции потерь, который пропорционален сумме квадратов элементов матрицы весов. Она используется для уменьшения влияния больших весов и предотвращения переобучения модели. L1 регуляризация добавляет “штраф” к функции потерь, который пропорционален сумме абсолютных значений элементов матрицы весов. Она используется для создания разреженных моделей и отбора признаков.
При использовании функции потерь MSE и L2 регуляризации с параметрами скорости обучения (learning rate) равными 0.05 и коэффициентом регуляризации (reg_coeff) равным 0.05, градиентный спуск сходится к оптимальным весам модели. На каждой итерации градиентного спуска значения эмпирического риска уменьшаются, а значения градиента уменьшаются и становятся близкими к нулю. Это позволяет модели приближаться к оптимальным весам, которые минимизируют функцию потерь и учитывают регуляризацию. Градиентный спуск с функцией потерь MAE и L1 регуляризацией также позволяет модели приближаться к оптимальным весам, которые минимизируют функцию потерь и учитывают регуляризацию. 
Реализация линейной регрессии с использованием библиотеки sklearn и параметрами Ridge регуляризации (alpha) равными 0.05 позволяет достичь среднеквадратичной ошибки (MSE) равной 42.53541245128315.
